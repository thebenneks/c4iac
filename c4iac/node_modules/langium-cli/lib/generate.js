"use strict";
/******************************************************************************
 * Copyright 2021 TypeFox GmbH
 * This program and the accompanying materials are made available under the
 * terms of the MIT License, which is available in the project root.
 ******************************************************************************/
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.generate = void 0;
const fs_extra_1 = __importDefault(require("fs-extra"));
const langium_1 = require("langium");
const internal_grammar_util_1 = require("langium/lib/grammar/internal-grammar-util");
const node_1 = require("langium/node");
const path_1 = __importDefault(require("path"));
const vscode_uri_1 = require("vscode-uri");
const ast_generator_1 = require("./generator/ast-generator");
const grammar_serializer_1 = require("./generator/grammar-serializer");
const module_generator_1 = require("./generator/module-generator");
const textmate_generator_1 = require("./generator/highlighting/textmate-generator");
const monarch_generator_1 = require("./generator/highlighting/monarch-generator");
const util_1 = require("./generator/util");
const package_1 = require("./package");
const parser_validation_1 = require("./parser-validation");
const chalk_1 = __importDefault(require("chalk"));
const { shared: sharedServices, grammar: grammarServices } = (0, langium_1.createLangiumGrammarServices)(node_1.NodeFileSystem);
const documents = sharedServices.workspace.LangiumDocuments;
function eagerLoad(document, uris = new Set()) {
    const uriString = document.uri.toString();
    if (!uris.has(uriString)) {
        uris.add(uriString);
        const grammar = document.parseResult.value;
        if (langium_1.GrammarAST.isGrammar(grammar)) {
            for (const imp of grammar.imports) {
                const importedGrammar = (0, internal_grammar_util_1.resolveImport)(documents, imp);
                if (importedGrammar) {
                    const importedDoc = (0, langium_1.getDocument)(importedGrammar);
                    eagerLoad(importedDoc, uris);
                }
            }
        }
    }
    return Array.from(uris).map(e => vscode_uri_1.URI.parse(e));
}
/**
 * Creates a map that contains elements of all grammars.
 * This includes both input grammars and their transitive dependencies.
 */
function mapGrammarElements(grammars, visited = new Set(), map = new Map()) {
    for (const grammar of grammars) {
        const doc = (0, langium_1.getDocument)(grammar);
        const uriString = doc.uri.toString();
        if (!visited.has(uriString)) {
            visited.add(uriString);
            map.set(grammar, grammar.rules
                .concat(grammar.types)
                .concat(grammar.interfaces));
            const importedGrammars = grammar.imports.map(e => (0, internal_grammar_util_1.resolveImport)(documents, e));
            mapGrammarElements(importedGrammars, visited, map);
        }
    }
    return map;
}
function embedReferencedGrammar(grammar, map) {
    var _a;
    const allGrammars = (0, internal_grammar_util_1.resolveTransitiveImports)(documents, grammar);
    for (const importedGrammar of allGrammars) {
        const grammarElements = (_a = map.get(importedGrammar)) !== null && _a !== void 0 ? _a : [];
        for (const element of grammarElements) {
            const shallowCopy = Object.assign({}, element);
            // Deactivate copied entry rule
            if (langium_1.GrammarAST.isParserRule(shallowCopy)) {
                shallowCopy.entry = false;
            }
            if (langium_1.GrammarAST.isAbstractRule(shallowCopy)) {
                grammar.rules.push(shallowCopy);
            }
            else if (langium_1.GrammarAST.isType(shallowCopy)) {
                grammar.types.push(shallowCopy);
            }
            else if (langium_1.GrammarAST.isInterface(shallowCopy)) {
                grammar.interfaces.push(shallowCopy);
            }
            else {
                throw new Error('Received invalid grammar element while generating project with multiple languages');
            }
        }
    }
    // Remove all imports, as their contents are now available in the grammar
    grammar.imports = [];
    // Link newly added elements to grammar
    (0, langium_1.linkContentToContainer)(grammar);
}
async function buildAll(config) {
    for (const doc of documents.all) {
        documents.invalidateDocument(doc.uri);
    }
    const map = new Map();
    const relPath = config[package_1.RelativePath];
    for (const languageConfig of config.languages) {
        const absGrammarPath = vscode_uri_1.URI.file(path_1.default.resolve(relPath, languageConfig.grammar));
        const document = documents.getOrCreateDocument(absGrammarPath);
        const allUris = eagerLoad(document);
        await sharedServices.workspace.DocumentBuilder.update(allUris, []);
    }
    for (const doc of documents.all) {
        await sharedServices.workspace.DocumentBuilder.build([doc]);
        map.set(doc.uri.fsPath, doc);
    }
    return map;
}
async function generate(config, options) {
    var _a, _b;
    if (!config.languages || config.languages.length === 0) {
        (0, util_1.log)('error', options, 'No languages specified in config.');
        return 'failure';
    }
    const all = await buildAll(config);
    let hasErrors = false;
    for (const [path, document] of all) {
        const diagnostics = (_a = document.diagnostics) !== null && _a !== void 0 ? _a : [];
        for (const diagnostic of diagnostics) {
            const message = `${(0, package_1.getFilePath)(path, config)}:${diagnostic.range.start.line + 1}:${diagnostic.range.start.character + 1} - ${diagnostic.message}`;
            if (diagnostic.severity === 1) {
                (0, util_1.log)('error', options, chalk_1.default.red(message));
            }
            else if (diagnostic.severity === 2) {
                (0, util_1.log)('warn', options, chalk_1.default.yellow(message));
            }
            else {
                (0, util_1.log)('log', options, message);
            }
        }
        if (!hasErrors) {
            hasErrors = diagnostics.length > 0 && diagnostics.some(e => e.severity === 1);
        }
    }
    if (hasErrors) {
        (0, util_1.log)('error', options, `Langium generator ${chalk_1.default.red.bold('failed')}.`);
        return 'failure';
    }
    const grammars = [];
    const configMap = new Map();
    const relPath = config[package_1.RelativePath];
    for (const languageConfig of config.languages) {
        const absGrammarPath = vscode_uri_1.URI.file(path_1.default.resolve(relPath, languageConfig.grammar)).fsPath;
        const document = all.get(absGrammarPath);
        if (document) {
            const grammar = document.parseResult.value;
            if (!grammar.isDeclared) {
                (0, util_1.log)('error', options, chalk_1.default.red(`${absGrammarPath}: The entry grammar must start with the 'grammar' keyword.`));
                return 'failure';
            }
            grammars.push(grammar);
            configMap.set(grammar, languageConfig);
        }
    }
    const grammarElements = mapGrammarElements(grammars);
    for (const grammar of grammars) {
        embedReferencedGrammar(grammar, grammarElements);
        // Create and validate the in-memory parser
        const parserAnalysis = (0, parser_validation_1.validateParser)(grammar, config, configMap, grammarServices);
        if (parserAnalysis instanceof Error) {
            (0, util_1.log)('error', options, chalk_1.default.red(parserAnalysis.toString()));
            return 'failure';
        }
    }
    // Generate the output files
    const output = path_1.default.resolve(relPath, (_b = config.out) !== null && _b !== void 0 ? _b : 'src/generated');
    (0, util_1.log)('log', options, `Writing generated files to ${chalk_1.default.white.bold(output)}`);
    if (await rmdirWithFail(output, ['ast.ts', 'grammar.ts', 'module.ts'], options)) {
        return 'failure';
    }
    if (await mkdirWithFail(output, options)) {
        return 'failure';
    }
    const genAst = (0, ast_generator_1.generateAst)(grammarServices, grammars, config);
    await writeWithFail(path_1.default.resolve(output, 'ast.ts'), genAst, options);
    const serializedGrammar = (0, grammar_serializer_1.serializeGrammar)(grammarServices, grammars, config);
    await writeWithFail(path_1.default.resolve(output, 'grammar.ts'), serializedGrammar, options);
    const genModule = (0, module_generator_1.generateModule)(grammars, config, configMap);
    await writeWithFail(path_1.default.resolve(output, 'module.ts'), genModule, options);
    for (const grammar of grammars) {
        const languageConfig = configMap.get(grammar);
        if (languageConfig === null || languageConfig === void 0 ? void 0 : languageConfig.textMate) {
            const genTmGrammar = (0, textmate_generator_1.generateTextMate)(grammar, languageConfig);
            const textMatePath = path_1.default.resolve(relPath, languageConfig.textMate.out);
            (0, util_1.log)('log', options, `Writing textmate grammar to ${chalk_1.default.white.bold(textMatePath)}`);
            await writeHighlightGrammar(genTmGrammar, textMatePath, options);
        }
        if (languageConfig === null || languageConfig === void 0 ? void 0 : languageConfig.monarch) {
            const genMonarchGrammar = (0, monarch_generator_1.generateMonarch)(grammar, languageConfig);
            const monarchPath = path_1.default.resolve(relPath, languageConfig.monarch.out);
            (0, util_1.log)('log', options, `Writing monarch grammar to ${chalk_1.default.white.bold(monarchPath)}`);
            await writeHighlightGrammar(genMonarchGrammar, monarchPath, options);
        }
    }
    return 'success';
}
exports.generate = generate;
/**
 * Writes contents of a grammar for syntax highlighting to a file, logging any errors and continuing without throwing
 * @param grammar Grammar contents to write
 * @param grammarPath Path to write, verifying the parent dir exists first
 * @param options Generation options
 */
async function writeHighlightGrammar(grammar, grammarPath, options) {
    const parentDir = path_1.default.dirname(grammarPath).split(path_1.default.sep).pop();
    parentDir && await mkdirWithFail(parentDir, options);
    await writeWithFail(grammarPath, grammar, options);
}
async function rmdirWithFail(dirPath, expectedFiles, options) {
    try {
        let deleteDir = true;
        const dirExists = await fs_extra_1.default.pathExists(dirPath);
        if (dirExists) {
            const existingFiles = await fs_extra_1.default.readdir(dirPath);
            const unexpectedFiles = existingFiles.filter(file => !expectedFiles.includes(path_1.default.basename(file)));
            if (unexpectedFiles.length > 0) {
                (0, util_1.log)('log', options, `Found unexpected files in the generated directory: ${unexpectedFiles.map(e => chalk_1.default.yellow(e)).join(', ')}`);
                deleteDir = await (0, util_1.getUserChoice)('Do you want to delete the files?', ['yes', 'no'], 'yes') === 'yes';
            }
            if (deleteDir) {
                await fs_extra_1.default.remove(dirPath);
            }
        }
        return false;
    }
    catch (e) {
        (0, util_1.log)('error', options, `Failed to delete directory ${chalk_1.default.red.bold(dirPath)}`, e);
        return true;
    }
}
async function mkdirWithFail(path, options) {
    try {
        await fs_extra_1.default.mkdirs(path);
        return false;
    }
    catch (e) {
        (0, util_1.log)('error', options, `Failed to create directory ${chalk_1.default.red.bold(path)}`, e);
        return true;
    }
}
async function writeWithFail(path, content, options) {
    try {
        await fs_extra_1.default.writeFile(path, content);
    }
    catch (e) {
        (0, util_1.log)('error', options, `Failed to write file to ${chalk_1.default.red.bold(path)}`, e);
    }
}
//# sourceMappingURL=generate.js.map