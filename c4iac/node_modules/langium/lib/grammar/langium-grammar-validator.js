"use strict";
/******************************************************************************
 * Copyright 2021 TypeFox GmbH
 * This program and the accompanying materials are made available under the
 * terms of the MIT License, which is available in the project root.
 ******************************************************************************/
var __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    var desc = Object.getOwnPropertyDescriptor(m, k);
    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
      desc = { enumerable: true, get: function() { return m[k]; } };
    }
    Object.defineProperty(o, k2, desc);
}) : (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
}));
var __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {
    Object.defineProperty(o, "default", { enumerable: true, value: v });
}) : function(o, v) {
    o["default"] = v;
});
var __importStar = (this && this.__importStar) || function (mod) {
    if (mod && mod.__esModule) return mod;
    var result = {};
    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);
    __setModuleDefault(result, mod);
    return result;
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.LangiumGrammarValidator = exports.IssueCodes = exports.LangiumGrammarValidationRegistry = void 0;
const vscode_languageserver_types_1 = require("vscode-languageserver-types");
const vscode_uri_1 = require("vscode-uri");
const ast_util_1 = require("../utils/ast-util");
const collections_1 = require("../utils/collections");
const cst_util_1 = require("../utils/cst-util");
const grammar_util_1 = require("../utils/grammar-util");
const stream_1 = require("../utils/stream");
const uri_util_1 = require("../utils/uri-util");
const validation_registry_1 = require("../validation/validation-registry");
const ast = __importStar(require("./generated/ast"));
const ast_1 = require("./generated/ast");
const internal_grammar_util_1 = require("./internal-grammar-util");
const type_validator_1 = require("./type-system/type-validator");
class LangiumGrammarValidationRegistry extends validation_registry_1.ValidationRegistry {
    constructor(services) {
        super(services);
        const validator = services.validation.LangiumGrammarValidator;
        const checks = {
            Action: validator.checkActionTypeUnions,
            AbstractRule: validator.checkRuleName,
            Assignment: [
                validator.checkAssignmentWithFeatureName,
                validator.checkAssignmentToFragmentRule
            ],
            ParserRule: [
                validator.checkParserRuleDataType,
                validator.checkRuleParametersUsed
            ],
            TerminalRule: [
                validator.checkTerminalRuleReturnType,
                validator.checkHiddenTerminalRule,
                validator.checkEmptyTerminalRule
            ],
            Keyword: validator.checkKeyword,
            UnorderedGroup: validator.checkUnorderedGroup,
            Grammar: [
                validator.checkGrammarName,
                validator.checkEntryGrammarRule,
                validator.checkUniqueRuleName,
                validator.checkUniqueTypeName,
                validator.checkUniqueImportedRules,
                validator.checkDuplicateImportedGrammar,
                validator.checkGrammarHiddenTokens,
                validator.checkGrammarForUnusedRules,
                validator.checkGrammarImports,
                validator.checkGrammarTypeUnions,
                validator.checkGrammarTypeInfer,
                validator.checkTypesConsistency,
                validator.checkPropertyNameDuplication
            ],
            GrammarImport: validator.checkPackageImport,
            CharacterRange: validator.checkInvalidCharacterRange,
            RuleCall: [
                validator.checkUsedHiddenTerminalRule,
                validator.checkUsedFragmentTerminalRule,
                validator.checkRuleCallParameters,
            ],
            TerminalRuleCall: validator.checkUsedHiddenTerminalRule,
            CrossReference: [
                validator.checkCrossReferenceSyntax,
                validator.checkCrossRefNameAssignment,
                validator.checkCrossRefTerminalType,
                validator.checkCrossRefType
            ],
            AtomType: [
                validator.checkAtomTypeRefType,
                validator.checkFragmentsInTypes
            ]
        };
        this.register(checks, validator);
    }
}
exports.LangiumGrammarValidationRegistry = LangiumGrammarValidationRegistry;
var IssueCodes;
(function (IssueCodes) {
    IssueCodes.GrammarNameUppercase = 'grammar-name-uppercase';
    IssueCodes.RuleNameUppercase = 'rule-name-uppercase';
    IssueCodes.HiddenGrammarTokens = 'hidden-grammar-tokens';
    IssueCodes.UseRegexTokens = 'use-regex-tokens';
    IssueCodes.EntryRuleTokenSyntax = 'entry-rule-token-syntax';
    IssueCodes.CrossRefTokenSyntax = 'cross-ref-token-syntax';
    IssueCodes.MissingImport = 'missing-import';
    IssueCodes.UnnecessaryFileExtension = 'unnecessary-file-extension';
    IssueCodes.InvalidReturns = 'invalid-returns';
    IssueCodes.InvalidInfers = 'invalid-infers';
    IssueCodes.MissingInfer = 'missing-infer';
    IssueCodes.SuperfluousInfer = 'superfluous-infer';
    IssueCodes.OptionalUnorderedGroup = 'optional-unordered-group';
})(IssueCodes = exports.IssueCodes || (exports.IssueCodes = {}));
class LangiumGrammarValidator {
    constructor(services) {
        this.references = services.references.References;
        this.documents = services.shared.workspace.LangiumDocuments;
    }
    checkGrammarName(grammar, accept) {
        if (grammar.name) {
            const firstChar = grammar.name.substring(0, 1);
            if (firstChar.toUpperCase() !== firstChar) {
                accept('warning', 'Grammar name should start with an upper case letter.', { node: grammar, property: 'name', code: IssueCodes.GrammarNameUppercase });
            }
        }
    }
    checkEntryGrammarRule(grammar, accept) {
        const entryRules = grammar.rules.filter(e => ast.isParserRule(e) && e.entry);
        if (grammar.isDeclared && entryRules.length === 0) {
            const possibleEntryRule = grammar.rules.find(e => ast.isParserRule(e) && !(0, internal_grammar_util_1.isDataTypeRule)(e));
            if (possibleEntryRule) {
                accept('error', 'The grammar is missing an entry parser rule. This rule can be an entry one.', { node: possibleEntryRule, property: 'name', code: IssueCodes.EntryRuleTokenSyntax });
            }
            else {
                accept('error', 'This grammar is missing an entry parser rule.', { node: grammar, property: 'name' });
            }
        }
        else if (!grammar.isDeclared && entryRules.length >= 1) {
            entryRules.forEach(rule => accept('error', 'Cannot declare entry rules for unnamed grammars.', { node: rule, property: 'name' }));
        }
        else if (entryRules.length > 1) {
            entryRules.forEach(rule => accept('error', 'The entry rule has to be unique.', { node: rule, property: 'name' }));
        }
        else if (entryRules.length === 1 && (0, internal_grammar_util_1.isDataTypeRule)(entryRules[0])) {
            accept('error', 'The entry rule cannot be a data type rule.', { node: entryRules[0], property: 'name' });
        }
    }
    /**
     * Check whether any rule defined in this grammar is a duplicate of an already defined rule or an imported rule
     */
    checkUniqueRuleName(grammar, accept) {
        const extractor = (grammar) => (0, stream_1.stream)(grammar.rules).filter(rule => !isEmptyRule(rule));
        this.checkUniqueName(grammar, accept, extractor, 'rule');
    }
    /**
     * Check whether any type defined in this grammar is a duplicate of an already defined type or an imported type
     */
    checkUniqueTypeName(grammar, accept) {
        const extractor = (grammar) => (0, stream_1.stream)(grammar.types).concat(grammar.interfaces);
        this.checkUniqueName(grammar, accept, extractor, 'type');
    }
    checkUniqueName(grammar, accept, extractor, uniqueObjName) {
        const map = new collections_1.MultiMap();
        extractor(grammar).forEach(e => map.add(e.name, e));
        for (const [, types] of map.entriesGroupedByKey()) {
            if (types.length > 1) {
                types.forEach(e => {
                    accept('error', `A ${uniqueObjName}'s name has to be unique.`, { node: e, property: 'name' });
                });
            }
        }
        const imported = new Set();
        const resolvedGrammars = (0, internal_grammar_util_1.resolveTransitiveImports)(this.documents, grammar);
        for (const resolvedGrammar of resolvedGrammars) {
            extractor(resolvedGrammar).forEach(e => imported.add(e.name));
        }
        for (const name of map.keys()) {
            if (imported.has(name)) {
                const types = map.get(name);
                types.forEach(e => {
                    accept('error', `A ${uniqueObjName} with the name '${e.name}' already exists in an imported grammar.`, { node: e, property: 'name' });
                });
            }
        }
    }
    checkDuplicateImportedGrammar(grammar, accept) {
        const importMap = new collections_1.MultiMap();
        for (const imp of grammar.imports) {
            const resolvedGrammar = (0, internal_grammar_util_1.resolveImport)(this.documents, imp);
            if (resolvedGrammar) {
                importMap.add(resolvedGrammar, imp);
            }
        }
        for (const [, imports] of importMap.entriesGroupedByKey()) {
            if (imports.length > 1) {
                imports.forEach((imp, i) => {
                    if (i > 0) {
                        accept('warning', 'The grammar is already being directly imported.', { node: imp, tags: [vscode_languageserver_types_1.DiagnosticTag.Unnecessary] });
                    }
                });
            }
        }
    }
    /**
     * Compared to the validation above, this validation only checks whether two imported grammars export the same grammar rule.
     */
    checkUniqueImportedRules(grammar, accept) {
        const imports = new Map();
        for (const imp of grammar.imports) {
            const importedGrammars = (0, internal_grammar_util_1.resolveTransitiveImports)(this.documents, imp);
            imports.set(imp, importedGrammars);
        }
        const allDuplicates = new collections_1.MultiMap();
        for (const outerImport of grammar.imports) {
            const outerGrammars = imports.get(outerImport);
            for (const innerImport of grammar.imports) {
                if (outerImport === innerImport) {
                    continue;
                }
                const innerGrammars = imports.get(innerImport);
                const duplicates = this.getDuplicateExportedRules(outerGrammars, innerGrammars);
                for (const duplicate of duplicates) {
                    allDuplicates.add(outerImport, duplicate);
                }
            }
        }
        for (const imp of grammar.imports) {
            const duplicates = allDuplicates.get(imp);
            if (duplicates.length > 0) {
                accept('error', 'Some rules exported by this grammar are also included in other imports: ' + (0, stream_1.stream)(duplicates).distinct().join(', '), { node: imp, property: 'path' });
            }
        }
    }
    getDuplicateExportedRules(outer, inner) {
        const exclusiveOuter = outer.filter(g => !inner.includes(g));
        const outerRules = exclusiveOuter.flatMap(e => e.rules);
        const innerRules = inner.flatMap(e => e.rules);
        const duplicates = new Set();
        for (const outerRule of outerRules) {
            const outerName = outerRule.name;
            for (const innerRule of innerRules) {
                const innerName = innerRule.name;
                if (outerName === innerName) {
                    duplicates.add(innerRule.name);
                }
            }
        }
        return duplicates;
    }
    checkGrammarTypeInfer(grammar, accept) {
        var _a, _b;
        const types = new Set();
        for (const type of grammar.types) {
            types.add(type.name);
        }
        for (const interfaceType of grammar.interfaces) {
            types.add(interfaceType.name);
        }
        // Collect type/interface definitions from imported grammars
        (0, internal_grammar_util_1.resolveTransitiveImports)(this.documents, grammar).forEach((grammar) => {
            grammar.types.forEach(type => types.add(type.name));
            grammar.interfaces.forEach(iface => types.add(iface.name));
        });
        for (const rule of grammar.rules.filter(ast.isParserRule)) {
            if (isEmptyRule(rule)) {
                continue;
            }
            const isDataType = (0, internal_grammar_util_1.isDataTypeRule)(rule);
            const isInfers = !rule.returnType && !rule.dataType;
            const ruleTypeName = (0, internal_grammar_util_1.getTypeName)(rule);
            if (!isDataType && ruleTypeName && types.has(ruleTypeName) === isInfers) {
                const keywordNode = isInfers ? (0, grammar_util_1.findNodeForKeyword)(rule.$cstNode, 'infer') : (0, grammar_util_1.findNodeForKeyword)(rule.$cstNode, 'returns');
                accept('error', getMessage(ruleTypeName, isInfers), {
                    node: (_a = rule.inferredType) !== null && _a !== void 0 ? _a : rule,
                    property: 'name',
                    code: isInfers ? IssueCodes.InvalidInfers : IssueCodes.InvalidReturns,
                    data: keywordNode && (0, cst_util_1.toDocumentSegment)(keywordNode)
                });
            }
            else if (isDataType && isInfers) {
                const inferNode = (0, grammar_util_1.findNodeForKeyword)(rule.$cstNode, 'infer');
                accept('error', 'Data type rules cannot infer a type.', {
                    node: rule,
                    property: 'inferredType',
                    code: IssueCodes.InvalidInfers,
                    data: inferNode && (0, cst_util_1.toDocumentSegment)(inferNode)
                });
            }
        }
        for (const action of (0, ast_util_1.streamAllContents)(grammar).filter(ast.isAction)) {
            const actionType = this.getActionType(action);
            if (actionType) {
                const isInfers = !!action.inferredType;
                const typeName = (0, internal_grammar_util_1.getTypeName)(action);
                if (action.type && types.has(typeName) === isInfers) {
                    const keywordNode = isInfers ? (0, grammar_util_1.findNodeForKeyword)(action.$cstNode, 'infer') : (0, grammar_util_1.findNodeForKeyword)(action.$cstNode, '{');
                    accept('error', getMessage(typeName, isInfers), {
                        node: action,
                        property: 'type',
                        code: isInfers ? IssueCodes.SuperfluousInfer : IssueCodes.MissingInfer,
                        data: keywordNode && (0, cst_util_1.toDocumentSegment)(keywordNode)
                    });
                }
                else if (actionType && types.has(typeName) && isInfers) {
                    // error: action infers type that is already defined
                    if (action.$cstNode) {
                        const inferredTypeNode = (0, grammar_util_1.findNodeForProperty)((_b = action.inferredType) === null || _b === void 0 ? void 0 : _b.$cstNode, 'name');
                        const keywordNode = (0, grammar_util_1.findNodeForKeyword)(action.$cstNode, '{');
                        if (inferredTypeNode && keywordNode) {
                            // remove everything from the opening { up to the type name
                            // we may lose comments in-between, but this can be undone as needed
                            accept('error', `${typeName} is a declared type and cannot be redefined.`, {
                                node: action,
                                property: 'type',
                                code: IssueCodes.SuperfluousInfer,
                                data: {
                                    start: keywordNode.range.end,
                                    end: inferredTypeNode.range.start
                                }
                            });
                        }
                    }
                }
            }
        }
        function getMessage(name, infer) {
            if (infer) {
                return `The type '${name}' is already explicitly declared and cannot be inferred.`;
            }
            else {
                return `The type '${name}' is not explicitly declared and must be inferred.`;
            }
        }
    }
    getActionType(rule) {
        var _a;
        if (rule.type) {
            return (_a = rule.type) === null || _a === void 0 ? void 0 : _a.ref;
        }
        else if (rule.inferredType) {
            return rule.inferredType;
        }
        return undefined;
    }
    checkGrammarHiddenTokens(grammar, accept) {
        if (grammar.definesHiddenTokens) {
            accept('error', 'Hidden terminals are declared at the terminal definition.', { node: grammar, property: 'definesHiddenTokens', code: IssueCodes.HiddenGrammarTokens });
        }
    }
    checkHiddenTerminalRule(terminalRule, accept) {
        if (terminalRule.hidden && terminalRule.fragment) {
            accept('error', 'Cannot use terminal fragments as hidden tokens.', { node: terminalRule, property: 'hidden' });
        }
    }
    checkEmptyTerminalRule(terminalRule, accept) {
        try {
            const regex = (0, internal_grammar_util_1.terminalRegex)(terminalRule);
            if (new RegExp(regex).test('')) {
                accept('error', 'This terminal could match an empty string.', { node: terminalRule, property: 'name' });
            }
        }
        catch (_a) {
            // In case the terminal can't be transformed into a regex, we throw an error
            // As this indicates unresolved cross references or parser errors, we can ignore this here
        }
    }
    checkUsedHiddenTerminalRule(ruleCall, accept) {
        const parentRule = (0, ast_util_1.getContainerOfType)(ruleCall, (n) => ast.isTerminalRule(n) || ast.isParserRule(n));
        if (parentRule) {
            if ('hidden' in parentRule && parentRule.hidden) {
                return;
            }
            const ref = ruleCall.rule.ref;
            if (ast.isTerminalRule(ref) && ref.hidden) {
                accept('error', 'Cannot use hidden terminal in non-hidden rule', { node: ruleCall, property: 'rule' });
            }
        }
    }
    checkUsedFragmentTerminalRule(ruleCall, accept) {
        const terminal = ruleCall.rule.ref;
        if (ast.isTerminalRule(terminal) && terminal.fragment) {
            const parentRule = (0, ast_util_1.getContainerOfType)(ruleCall, ast.isParserRule);
            if (parentRule) {
                accept('error', 'Cannot use terminal fragments as part of parser rules.', { node: ruleCall, property: 'rule' });
            }
        }
    }
    checkCrossReferenceSyntax(crossRef, accept) {
        if (crossRef.deprecatedSyntax) {
            accept('error', "'|' is deprecated. Please, use ':' instead.", { node: crossRef, property: 'deprecatedSyntax', code: IssueCodes.CrossRefTokenSyntax });
        }
    }
    checkPackageImport(imp, accept) {
        const resolvedGrammar = (0, internal_grammar_util_1.resolveImport)(this.documents, imp);
        if (resolvedGrammar === undefined) {
            accept('error', 'Import cannot be resolved.', { node: imp, property: 'path' });
        }
        else if (imp.path.endsWith('.langium')) {
            accept('warning', 'Imports do not need file extensions.', { node: imp, property: 'path', code: IssueCodes.UnnecessaryFileExtension });
        }
    }
    checkGrammarImports(grammar, accept) {
        // Compute transitive grammar dependencies once for each grammar
        const importedGrammars = new Set((0, internal_grammar_util_1.resolveTransitiveImports)(this.documents, grammar).map(e => (0, ast_util_1.getDocument)(e)));
        (0, ast_util_1.streamAllContents)(grammar).forEach(e => {
            if (ast.isRuleCall(e) || ast.isTerminalRuleCall(e)) {
                this.checkRuleCallImport(e, importedGrammars, accept);
            }
        });
    }
    checkRuleCallImport(ruleCall, importedDocuments, accept) {
        var _a;
        const ref = ruleCall.rule.ref;
        if (ref) {
            const refDoc = (0, ast_util_1.getDocument)(ref);
            const document = (0, ast_util_1.getDocument)(ruleCall);
            const grammar = document.parseResult.value;
            // Only check if the rule is sourced from another document
            if (ast.isGrammar(grammar) && refDoc !== document && !importedDocuments.has(refDoc)) {
                let relative = (0, uri_util_1.relativeURI)(vscode_uri_1.Utils.dirname(document.uri), refDoc.uri);
                if (relative.endsWith('.langium')) {
                    relative = relative.substring(0, relative.length - '.langium'.length);
                }
                if (!relative.startsWith('.')) {
                    relative = './' + relative;
                }
                accept('error', `Referenced rule "${(_a = ruleCall.rule.ref) === null || _a === void 0 ? void 0 : _a.name}" is not imported.`, {
                    node: ruleCall,
                    property: 'rule',
                    code: IssueCodes.MissingImport,
                    data: relative
                });
            }
        }
    }
    checkGrammarTypeUnions(grammar, accept) {
        for (const rule of grammar.rules) {
            if (ast.isParserRule(rule) && ast.isType(rule.returnType)) {
                accept('error', 'Rules are not allowed to return union types.', { node: rule, property: 'returnType' });
            }
        }
        for (const interfaceType of grammar.interfaces) {
            interfaceType.superTypes.forEach((superType, i) => {
                if (superType.ref && ast.isType(superType.ref)) {
                    accept('error', 'Interfaces cannot extend union types.', { node: interfaceType, property: 'superTypes', index: i });
                }
                // TODO: needs to be reimplemented once the type system has been refactored
                // else if(superType.ref && ast.isParserRule(superType.ref)) {
                //     // collect just the beginning of whatever inferred types this standalone rule produces
                //     // looking to exclude anything that would be a union down the line
                //     const inferred = collectInferredTypes([superType.ref as ast.ParserRule], []);
                //     if(inferred.unions.length > 0) {
                //         // inferred union type also cannot be extended
                //         accept('error', `An interface cannot extend a union type, which was inferred from parser rule ${superType.ref.name}.`, { node: interfaceType, property: 'superTypes', index: i });
                //     } else {
                //         // otherwise we'll allow it, but issue a warning against basing declared off of inferred types
                //         accept('warning', 'Extending an interface by a parser rule gives an ambiguous type, instead of the expected declared type.', { node: interfaceType, property: 'superTypes', index: i });
                //     }
                // }
            });
        }
    }
    checkActionTypeUnions(action, accept) {
        if (ast.isType(action.type)) {
            accept('error', 'Actions cannot create union types.', { node: action, property: 'type' });
        }
    }
    checkTypesConsistency(grammar, accept) {
        (0, type_validator_1.validateTypesConsistency)(grammar, accept);
    }
    checkPropertyNameDuplication(grammar, accept) {
        if (grammar.interfaces.length === 0)
            return;
        const nameToInterfaceInfo = (0, type_validator_1.collectAllInterfaces)(grammar);
        for (const interfaceName of grammar.interfaces.map(e => e.name)) {
            const propertyNameToNode = new collections_1.MultiMap();
            this.collectPropertyNamesForHierarchy(nameToInterfaceInfo, new Set(), propertyNameToNode, interfaceName);
            for (const [propertyName, nodes] of propertyNameToNode.entriesGroupedByKey()) {
                if (nodes.length < 2)
                    continue;
                for (const node of nodes) {
                    const errorMessage = `A property '${propertyName}' has to be unique for the whole hierarchy.`;
                    if (ast.isInterface(node)) {
                        const attributeNode = node.attributes.find(e => e.name === propertyName);
                        if (attributeNode) {
                            accept('error', errorMessage, { node: attributeNode, property: 'name' });
                        }
                    }
                    else {
                        (0, type_validator_1.applyErrorToAssignment)(node, accept)(propertyName, errorMessage);
                    }
                }
            }
        }
    }
    collectPropertyNamesForHierarchy(nameToInterfaceInfo, visited, result, interfaceName) {
        function collectPropertyNamesForHierarchyInternal(interfaceName) {
            if (visited.has(interfaceName))
                return;
            visited.add(interfaceName);
            const interfaceInfo = nameToInterfaceInfo.get(interfaceName);
            if (interfaceInfo) {
                interfaceInfo.type.properties.forEach(property => result.add(property.name, interfaceInfo.node));
                interfaceInfo.type.interfaceSuperTypes.forEach(superType => collectPropertyNamesForHierarchyInternal(superType));
            }
        }
        collectPropertyNamesForHierarchyInternal(interfaceName);
    }
    checkInvalidCharacterRange(range, accept) {
        if (range.right) {
            const message = 'Character ranges cannot use more than one character';
            let invalid = false;
            if (range.left.value.length > 1) {
                invalid = true;
                accept('error', message, { node: range.left, property: 'value' });
            }
            if (range.right.value.length > 1) {
                invalid = true;
                accept('error', message, { node: range.right, property: 'value' });
            }
            if (!invalid) {
                accept('hint', 'Consider using regex instead of character ranges', { node: range, code: IssueCodes.UseRegexTokens });
            }
        }
    }
    checkGrammarForUnusedRules(grammar, accept) {
        const reachableRules = (0, grammar_util_1.getAllReachableRules)(grammar, true);
        for (const rule of grammar.rules) {
            if (ast.isTerminalRule(rule) && rule.hidden || isEmptyRule(rule)) {
                continue;
            }
            if (!reachableRules.has(rule)) {
                accept('hint', 'This rule is declared but never referenced.', { node: rule, property: 'name', tags: [vscode_languageserver_types_1.DiagnosticTag.Unnecessary] });
            }
        }
    }
    checkRuleName(rule, accept) {
        if (rule.name && !isEmptyRule(rule)) {
            const firstChar = rule.name.substring(0, 1);
            if (firstChar.toUpperCase() !== firstChar) {
                accept('warning', 'Rule name should start with an upper case letter.', { node: rule, property: 'name', code: IssueCodes.RuleNameUppercase });
            }
        }
    }
    checkKeyword(keyword, accept) {
        if (keyword.value.length === 0) {
            accept('error', 'Keywords cannot be empty.', { node: keyword });
        }
        else if (keyword.value.trim().length === 0) {
            accept('error', 'Keywords cannot only consist of whitespace characters.', { node: keyword });
        }
        else if (/\s/g.test(keyword.value)) {
            accept('warning', 'Keywords should not contain whitespace characters.', { node: keyword });
        }
    }
    checkUnorderedGroup(unorderedGroup, accept) {
        unorderedGroup.elements.forEach((ele) => {
            if ((0, internal_grammar_util_1.isOptionalCardinality)(ele.cardinality)) {
                accept('error', 'Optional elements in Unordered groups are currently not supported', { node: ele, code: IssueCodes.OptionalUnorderedGroup });
            }
        });
    }
    checkRuleParametersUsed(rule, accept) {
        const parameters = rule.parameters;
        if (parameters.length > 0) {
            const allReferences = (0, ast_util_1.streamAllContents)(rule).filter(ast.isParameterReference);
            for (const parameter of parameters) {
                if (!allReferences.some(e => e.parameter.ref === parameter)) {
                    accept('hint', `Parameter '${parameter.name}' is unused.`, {
                        node: parameter,
                        tags: [vscode_languageserver_types_1.DiagnosticTag.Unnecessary]
                    });
                }
            }
        }
    }
    checkParserRuleDataType(rule, accept) {
        if (isEmptyRule(rule)) {
            return;
        }
        const hasDatatypeReturnType = rule.dataType;
        const isDataType = (0, internal_grammar_util_1.isDataTypeRule)(rule);
        if (!hasDatatypeReturnType && isDataType) {
            accept('error', 'This parser rule does not create an object. Add a primitive return type or an action to the start of the rule to force object instantiation.', { node: rule, property: 'name' });
        }
        else if (hasDatatypeReturnType && !isDataType) {
            accept('error', 'Normal parser rules are not allowed to return a primitive value. Use a datatype rule for that.', { node: rule, property: 'dataType' });
        }
    }
    checkAssignmentToFragmentRule(assignment, accept) {
        if ((0, ast_1.isRuleCall)(assignment.terminal) && (0, ast_1.isParserRule)(assignment.terminal.rule.ref) && assignment.terminal.rule.ref.fragment) {
            accept('error', `Cannot use fragment rule '${assignment.terminal.rule.ref.name}' for assignment of property '${assignment.feature}'.`, { node: assignment, property: 'terminal' });
        }
    }
    checkTerminalRuleReturnType(rule, accept) {
        var _a;
        if (((_a = rule.type) === null || _a === void 0 ? void 0 : _a.name) && !isPrimitiveType(rule.type.name)) {
            accept('error', "Terminal rules can only return primitive types like 'string', 'boolean', 'number', 'Date' or 'bigint'.", { node: rule.type, property: 'name' });
        }
    }
    checkRuleCallParameters(ruleCall, accept) {
        const rule = ruleCall.rule.ref;
        if (ast.isParserRule(rule)) {
            const expected = rule.parameters.length;
            const given = ruleCall.arguments.length;
            if (expected !== given) {
                accept('error', `Rule '${rule.name}' expects ${expected} arguments, but got ${given}.`, { node: ruleCall });
            }
        }
        else if (ast.isTerminalRule(rule) && ruleCall.arguments.length > 0) {
            accept('error', 'Terminal rules do not accept any arguments', { node: ruleCall });
        }
    }
    checkCrossRefNameAssignment(reference, accept) {
        if (!reference.terminal && reference.type.ref && !(0, grammar_util_1.findNameAssignment)(reference.type.ref)) {
            accept('error', 'Cannot infer terminal or data type rule for cross reference.', { node: reference, property: 'type' });
        }
    }
    checkCrossRefTerminalType(reference, accept) {
        if (ast.isRuleCall(reference.terminal) && ast.isParserRule(reference.terminal.rule.ref) && !(0, internal_grammar_util_1.isDataTypeRule)(reference.terminal.rule.ref)) {
            accept('error', 'Parser rules cannot be used for cross references.', { node: reference.terminal, property: 'rule' });
        }
    }
    checkCrossRefType(reference, accept) {
        const issue = this.checkReferenceToRuleButNotType(reference === null || reference === void 0 ? void 0 : reference.type);
        if (issue) {
            accept('error', issue, { node: reference, property: 'type' });
        }
    }
    checkAtomTypeRefType(atomType, accept) {
        if (atomType === null || atomType === void 0 ? void 0 : atomType.refType) {
            const issue = this.checkReferenceToRuleButNotType(atomType === null || atomType === void 0 ? void 0 : atomType.refType);
            if (issue) {
                accept('error', issue, { node: atomType, property: 'refType' });
            }
        }
    }
    checkFragmentsInTypes(atomType, accept) {
        var _a, _b;
        if (ast.isParserRule((_a = atomType.refType) === null || _a === void 0 ? void 0 : _a.ref) && ((_b = atomType.refType) === null || _b === void 0 ? void 0 : _b.ref.fragment)) {
            accept('error', 'Cannot use rule fragments in types.', { node: atomType, property: 'refType' });
        }
    }
    checkReferenceToRuleButNotType(type) {
        if (type && ast.isParserRule(type.ref) && !(0, internal_grammar_util_1.isDataTypeRule)(type.ref) && (type.ref.returnType || type.ref.inferredType)) {
            const typeName = (0, internal_grammar_util_1.getTypeName)(type.ref);
            if (typeName) {
                return `Use the rule type '${typeName}' instead of the typed rule name '${type.ref.name}' for cross references.`;
            }
        }
        return undefined;
    }
    checkAssignmentWithFeatureName(assignment, accept) {
        if (assignment.feature === 'name' && ast.isCrossReference(assignment.terminal)) {
            accept('warning', 'The "name" property is not recommended for cross-references.', { node: assignment, property: 'feature' });
        }
    }
}
exports.LangiumGrammarValidator = LangiumGrammarValidator;
const primitiveTypes = ['string', 'number', 'boolean', 'Date', 'bigint'];
function isPrimitiveType(type) {
    return primitiveTypes.includes(type);
}
function isEmptyRule(rule) {
    return !rule.definition || !rule.definition.$cstNode || rule.definition.$cstNode.length === 0;
}
//# sourceMappingURL=langium-grammar-validator.js.map